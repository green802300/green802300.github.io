---
layout: post
title: '1 机器人导航 简介'
date: 2019-08-20
author: Green
color: rgb(255,210,32)
cover: '../2019/08/20/cover.jpg'
tags: navigation
---

# 机器人导航简介

&#8195;&#8195;导航可以说是机器人最基本的功能之一，简单来说，导航就是机器人基于地图，实现从起始点前进到目标点的过程，这个过程中要求不发生碰撞并满足自身动力学模型（如不超过速度、加速度等限制）。

<div align="center">
  <img src="什么是导航.png" width="60%" height="60%"/>
</div>

&#8195;&#8195;将导航的任务进行细分，首先机器人在未知环境中需要使用激光传感器（或者是深度传感器）进行**地图**构建，然后根据构建的地图进行**定位**，有了地图和定位的基础，就可以根据目标点以及**感知**的障碍物信息进行**路径规划**了。我们可以将导航的要素归纳如下：

+ 地图
+ 定位
+ 感知
+ 路径规划。

<div align="center">
  <img src="导航元素.png" width="60%" height="60%"/>
</div>


## 地图

&#8195;&#8195;下面这张图是ROS中的一个地图，其实也就是一张普通的灰度图像。图像上的黑色像素表示障碍物，白色像素表示可行区域，灰色是未探索的区域。

<div align="center">
  <img src="地图示例.png" width="30%" height="30%"/>
</div>

&#8195;&#8195;一般来说，地图是通过[SLAM](https://baike.baidu.com/item/SLAM/7661974?fr=aladdin)(同时定位与建图)来构建的，这里就不展开了。


## 定位

&#8195;&#8195;定位是对机器人位置和姿态（一般简称位姿）的测量或估计，简单来说，通过定位，机器人可以知道自己在哪儿以及所面朝的方向。

<div align="center">
  <img src="定位.png" width="60%" height="60%"/>
</div>


## 感知

&#8195;&#8195;机器人是通过传感器来感知周围环境的。下面三个图是机器人常用的传感器，从左至右分别是超声波传感器，激光雷达，深度摄像头（与传统的摄像头区别在于加入了深度信息，可以测量像素点距离摄像头的距离）。

<div align="center">
  <img src="传感器.png" width="75%" height="75%"/>
</div>

&#8195;&#8195;通过这些传感器的数据，就可以对墙壁、路障等障碍物进行感知识别。

# ROS导航框架

&#8195;&#8195;这是[ROS wiki](http://wiki.ros.org/move_base)上的一张图，介绍了ROS导航的整体工作框架：

<figure align="center">
  <img src="导航框架.png" width="90%" height="90%"/>
</figure>

&#8195;&#8195;白色是已经提供给你的节点，灰色是可选的，蓝色是根据平台的差异而不同的节点。

&#8195;&#8195;首先，navigation框架里面的核心是中间的**move_base**，这是导航最重要的一个package，它负责运动规划，这里面有**global planner**和**local planner**，把路径规划问题分解为全局和局部两部分来解决，而这两个planner做出决策，要参考全局和局部的**costmap**代价地图。然后move_base还包括了一些**recovery behaviors**，让机器人在某些情况下，比如说碰到障碍物，卡住，会采取一些恢复措施。

&#8195;&#8195;我们先把move_base看成一个整体进行一定程度的简化，如下图所示。可以认为move_base就是一个路径规划的工具，然后分析move_base需要什么输入，然后它能输出给我们什么数据。

<figure align="center">
  <img src="简化导航框架.png" width="75%" height="75%"/>
</figure>

&#8195;&#8195;有这么几个数据是必须给的，一个是TransForms(tf)，路径规划当然得知道各个坐标系的变换关系了，尤其是当前机器人在地图的什么位置。那其中必不可少的是map->odom->base之间的tf，还有base到其他各个机器人零部件的tf。

&#8195;&#8195;还有就是Odemetry(odem)的数据，刚才tf只提供了位置和方向信息，但是实际路径规划，还要考虑速度和角速度，所以这里专门有一个odom来提供位置方向、线速度、角速度。这个odom注意，是一个topic，不是tf里的odom frame。类似的还有map，既是tf里的frame，也是一个topic。

&#8195;&#8195;除了odom之外，还有一个Laser，可以是激光雷达，可以是深度摄像头的点云，主要是用来帮助构建costmap，实现避障。

&#8195;&#8195;所以你需要提供的数据，通常来说就是这么几个，/map，/tf， /scan， /odom，以及目标点的信息。

&#8195;&#8195;那navigation 输出什么呢？很简单，输出的就是路径规划算出来的当前速度，/cmd_vel。


## Navigation Stack

Navigation Stack是一个ROS的功能包集，里面包含了ROS在路径规划、定位、地图、异常行为恢复等方面的package，如下表所示。这么多package，你可能会觉得很乱，不过不用担心，在使用中其实还是比较简单的。

| 包名       | 功能        |
| -----------| -----------|
| amcl  | 定位 |
| Fake_localization | 定位 |
| map_server | 提供地图 |
| move_base  | 路径规划节点 |
| nav_core  | 路径规划接口类 |
| base_local _planner  | 实现了Trajectory Rollout和DWA两种局部规划算法 |
| dwa_local _planner  | 重新实现了DWA局部规划算法 |
| parrot_planner  | 实现了较简单的全局规划算法 |
| navfn  | 实现了Dijkstra和A*全局规划算法 |
| global_planner | 重新实现了Dijkstra和A*全局规划算法 |
| clear_costmap _recovery | 实现了清除代价地图的恢复行为|
| rotate_recovery | 实现了旋转的恢复行为 |
| move_slow _ and_clear | 路径规划接口类 |
| costmap_2d | 二维代价地图 |
| voxel_grid | 三维小方块 |
| robot_pose _ekf  | 机器人位姿的卡尔曼滤波 |



## 参考资料

[1] http://wiki.ros.org/move_base

[2] http://wiki.ros.org/navigation

